# COCO2014

[Official website](https://cocodataset.org) | [Guide](https://www.v7labs.com/blog/coco-dataset-guide)

## Brief introduction

> Copied from the official website.

COCO is a large-scale object detection, segmentation, and captioning dataset. COCO has several features:

- Object segmentation
- Recognition in context
- Superpixel stuff segmentation
- 330K images (>200K labeled)
- 1.5 million object instances
- 80 object categories
- 91 stuff categories
- 5 captions per image
- 250,000 people with keypoints

## Statistics

**Numbers**: 164,062

**Splits** (train / valid / test): 82,783 / 40,504 / 40,775

**Karpathy Splits** (train / valid / test): 113,287 / 5,000 / 5,000

**Resolution**: Mostly around 640x480

## Usage

### Download

```shell
wget http://images.cocodataset.org/zips/train2014.zip
wget http://images.cocodataset.org/zips/val2014.zip
wget http://images.cocodataset.org/zips/test2014.zip
wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip
wget http://images.cocodataset.org/annotations/image_info_test2014.zip
unzip '*.zip'

# for "Karpathy split"
wget https://cs.stanford.edu/people/karpathy/deepimagesent/caption_datasets.zip
unzip caption_datasets.zip -d karpathy
```

### File structure

```text
root
├── train2014
│   ├── COCO_train2014_000000000009.jpg
│   ├── ...
│   └── COCO_train2014_000000581921.jpg
├── val2014
│   ├── COCO_val2014_000000000042.jpg
│   ├── ...
│   └── COCO_val2014_000000581929.jpg
├── test2014
│   ├── COCO_test2014_000000000001.jpg
│   ├── ...
│   └── COCO_test2014_000000581923.jpg
├── annotations
│   ├── captions_train2014.json
│   ├── captions_val2014.json
│   ├── instances_train2014.json
│   ├── instances_val2014.json
│   ├── person_keypoints_train2014.json
│   ├── person_keypoints_val2014.json
│   └── image_info_test2014.json
└── karpathy
    ├── dataset_coco.json
    ├── dataset_flickr8k.json  # not used
    └── dataset_flickr30k.json # not used
```

### Example

```python
from image_datasets import COCO2014Captions
 
train_set = COCO2014Captions(root='~/data/COCO2014', split='train')
valid_set = COCO2014Captions(root='~/data/COCO2014', split='valid')
test_set = COCO2014Captions(root='~/data/COCO2014', split='test')
print(len(train_set))  # 113287
print(len(valid_set))  # 5000
print(len(test_set))   # 5000
print(train_set[0][0]) # <PIL.Image.Image image mode=RGB size=640x480 at 0x7FEF4376E950>
print(train_set[0][1][0])  # A woman wearing a net on her head cutting a cake.
print(train_set[0][1][1])  # A woman cutting a large white sheet cake.
print(train_set[0][1][2])  # A woman wearing a hair net cutting a large sheet cake.
print(train_set[0][1][3])  # there is a woman that is cutting a white cake
print(train_set[0][1][4])  # A woman marking a cake with the back of a chef's knife.
```
